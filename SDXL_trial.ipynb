{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishardmunene/Stable-Diffusion-test/blob/train/SDXL_trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sGxmTWQ7BqJA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import psutil\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Union, List, Tuple\n",
        "\n",
        "import torch\n",
        "from torch import amp\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from diffusers import StableDiffusionXLPipeline, ControlNetModel\n",
        "from accelerate import Accelerator\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from typing import Dict, Any, List, Optional, Union, Tuple\n",
        "from dataclasses import dataclass\n",
        "import logging\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import logging\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from typing import Dict, Any, Optional\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdW3U3ihCSNt",
        "outputId": "79f6eb8a-4005-4e0a-f1ec-7d5108696e4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 2. Mount drive and setup paths\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ROOT_DIR = '/content/drive/MyDrive/SDXL_images'\n",
        "IMAGE_DIR = os.path.join(ROOT_DIR, 'landscape_images')\n",
        "OUTPUT_DIR = os.path.join(ROOT_DIR, 'generated_images')\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(ROOT_DIR, exist_ok=True)\n",
        "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# 3. Update ImageFolderDataset class\n",
        "class ImageFolderDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_size: Tuple[int, int] = (512, 512),\n",
        "        transform = None\n",
        "    ):\n",
        "        self.folder_path = Path(IMAGE_DIR)\n",
        "        self._validate_folder()\n",
        "\n",
        "        self.image_files = self._get_image_files()\n",
        "        self.image_size = image_size\n",
        "        self.transform = transform or self._default_transform()\n",
        "\n",
        "        print(f\"Loaded dataset with {len(self.image_files)} images from {IMAGE_DIR}\")\n",
        "\n",
        "    def _validate_folder(self):\n",
        "        if not self.folder_path.exists():\n",
        "            raise ValueError(f\"Image directory not found: {IMAGE_DIR}\")\n",
        "\n",
        "    def _get_image_files(self) -> List[Path]:\n",
        "        files = list(self.folder_path.glob(\"*.jpg\")) + \\\n",
        "                list(self.folder_path.glob(\"*.png\"))\n",
        "        if not files:\n",
        "            raise ValueError(f\"No images found in {IMAGE_DIR}\")\n",
        "        return files\n",
        "\n",
        "    def _default_transform(self):\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize(self.image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_files[idx]\n",
        "        try:\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "\n",
        "            return {\n",
        "                \"image\": image,\n",
        "                \"prompt\": f\"A landscape photo of {image_path.stem}\",\n",
        "                \"path\": str(image_path)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {image_path}: {e}\")\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VKjBY8vKBx88"
      },
      "outputs": [],
      "source": [
        "def monitor_memory():\n",
        "    \"\"\"Utility function to monitor memory usage.\"\"\"\n",
        "    gpu_memory = torch.cuda.memory_allocated() / 1024**2\n",
        "    ram_memory = psutil.Process().memory_info().rss / 1024**2\n",
        "    return {\n",
        "        \"gpu_memory_mb\": gpu_memory,\n",
        "        \"ram_memory_mb\": ram_memory\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IZo1g8VWCSNv"
      },
      "outputs": [],
      "source": [
        "class PromptProcessor:\n",
        "    def __init__(self, model_name: str = \"bert-base-uncased\"):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            model_name,\n",
        "            num_labels=2\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def process_prompt(self, prompt: str) -> Dict[str, Any]:\n",
        "        parameters = self._extract_parameters(prompt)\n",
        "        return parameters\n",
        "\n",
        "    def _extract_parameters(self, prompt: str) -> Dict[str, Any]:\n",
        "        params = {}\n",
        "        if \"large\" in prompt.lower():\n",
        "            params[\"size\"] = (1024, 1024)\n",
        "        elif \"small\" in prompt.lower():\n",
        "            params[\"size\"] = (256, 256)\n",
        "        else:\n",
        "            params[\"size\"] = (512, 512)\n",
        "        return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aGro1-oXB2gE"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class OptimizationConfig:\n",
        "    image_size: Tuple[int, int] = (256, 256)\n",
        "    precision: str = \"fp16\"  # or \"bf16\"\n",
        "    enable_checkpointing: bool = True\n",
        "    enable_attention_slicing: bool = True\n",
        "    enable_sequential_cpu_offload: bool = False\n",
        "    vae_slicing: bool = True\n",
        "\n",
        "class ProcessedPrompt:\n",
        "    raw_prompt: str\n",
        "    tokens: List[str]\n",
        "    parameters: Dict[str, Any]\n",
        "    intent: str\n",
        "    confidence: float\n",
        "\n",
        "class PromptProcessor:\n",
        "    def __init__(self, model_name: str = \"bert-base-uncased\"):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def process_prompt(self, prompt: str) -> ProcessedPrompt:\n",
        "        self.logger.info(f\"Processing prompt: {prompt}\")\n",
        "\n",
        "        # Tokenization\n",
        "        tokens = self.tokenizer.tokenize(prompt)\n",
        "\n",
        "        # Basic parameter extraction\n",
        "        parameters = self._extract_parameters(prompt)\n",
        "\n",
        "        # Simple intent classification\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(**inputs).logits\n",
        "            intent_id = torch.argmax(logits, dim=1).item()\n",
        "            confidence = torch.softmax(logits, dim=1)[0][intent_id].item()\n",
        "\n",
        "        return ProcessedPrompt(\n",
        "            raw_prompt=prompt,\n",
        "            tokens=tokens,\n",
        "            parameters=parameters,\n",
        "            intent=str(intent_id),\n",
        "            confidence=confidence\n",
        "        )\n",
        "\n",
        "    def _extract_parameters(self, prompt: str) -> Dict[str, Any]:\n",
        "        \"\"\"Extract parameters from prompt\"\"\"\n",
        "        # Basic parameter extraction\n",
        "        params = {}\n",
        "        # Add size detection\n",
        "        if \"large\" in prompt.lower():\n",
        "            params[\"size\"] = (1024, 1024)\n",
        "        elif \"small\" in prompt.lower():\n",
        "            params[\"size\"] = (256, 256)\n",
        "        else:\n",
        "            params[\"size\"] = (512, 512)\n",
        "\n",
        "        return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pz35mwanB611"
      },
      "outputs": [],
      "source": [
        "class OptimizedSDXL:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_id: str = \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "        config: Optional[OptimizationConfig] = None\n",
        "    ):\n",
        "        self.config = config or OptimizationConfig()\n",
        "        self.accelerator = Accelerator()\n",
        "        self.setup_pipeline(model_id)\n",
        "        self.optimizer = None\n",
        "        self.loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "    def setup_pipeline(self, model_id: str):\n",
        "        \"\"\"Setup and optimize the SDXL pipeline\"\"\"\n",
        "        try:\n",
        "            # Initialize pipeline with optimizations\n",
        "            self.pipeline = StableDiffusionXLPipeline.from_pretrained(\n",
        "                model_id,\n",
        "                torch_dtype=torch.float16 if self.config.precision == \"fp16\" else torch.bfloat16,\n",
        "                use_safetensors=True\n",
        "            )\n",
        "\n",
        "            # Apply memory optimizations\n",
        "            if self.config.enable_attention_slicing:\n",
        "                self.pipeline.enable_attention_slicing()\n",
        "\n",
        "            if self.config.enable_sequential_cpu_offload:\n",
        "                self.pipeline.enable_sequential_cpu_offload()\n",
        "\n",
        "            if self.config.vae_slicing:\n",
        "                self.pipeline.enable_vae_slicing()\n",
        "\n",
        "            # Move to accelerator device\n",
        "            self.pipeline = self.pipeline.to(self.accelerator.device)\n",
        "\n",
        "            # Enable gradient checkpointing if configured\n",
        "            if self.config.enable_checkpointing:\n",
        "                self.pipeline.unet.enable_gradient_checkpointing()\n",
        "\n",
        "            print(f\"Pipeline setup complete on device: {self.accelerator.device}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up pipeline: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def generate_image(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        negative_prompt: Optional[str] = None,\n",
        "        num_inference_steps: int = 50,\n",
        "        **kwargs\n",
        "    ):\n",
        "        \"\"\"Generate image with the pipeline\"\"\"\n",
        "        try:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                result = self.pipeline(\n",
        "                    prompt=prompt,\n",
        "                    negative_prompt=negative_prompt,\n",
        "                    num_inference_steps=num_inference_steps,\n",
        "                    **kwargs\n",
        "                ).images[0]\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating image: {str(e)}\")\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g6MalIiCCBH4"
      },
      "outputs": [],
      "source": [
        "class ProgressiveTrainer:\n",
        "    def __init__(self, sdxl_model: OptimizedSDXL):\n",
        "        self.model = sdxl_model\n",
        "        self.progressive_sizes = [(256, 256), (512, 512), (768, 768), (1024, 1024)]\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def train_progressive(self, dataset, num_epochs_per_size=5):\n",
        "        \"\"\"Implement progressive training with increasing image sizes.\"\"\"\n",
        "        for size in self.progressive_sizes:\n",
        "            try:\n",
        "                print(f\"Starting training at resolution {size}\")\n",
        "                # Update model config and resize dataset images if needed\n",
        "                self.model.config.image_size = size\n",
        "                resized_dataset = self.resize_dataset(dataset, size)\n",
        "                self.train_single_stage(resized_dataset, num_epochs_per_size)\n",
        "                print(f\"Completed training at resolution {size}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error during training at resolution {size}: {e}\")\n",
        "                continue\n",
        "\n",
        "    def resize_dataset(self, dataset, size):\n",
        "        \"\"\"Resize dataset images to target size.\"\"\"\n",
        "        # Implement dataset resizing logic here\n",
        "        # Placeholder implementation; modify as per dataset structure\n",
        "        return dataset\n",
        "\n",
        "    def train_single_stage(self, dataset, num_epochs):\n",
        "        \"\"\"Training loop for a single resolution stage.\"\"\"\n",
        "        try:\n",
        "            # Ensure the model and subcomponents are in training mode\n",
        "            if hasattr(self.model, 'train'):\n",
        "                self.model.train()\n",
        "            else:\n",
        "                self.model.pipeline.train()\n",
        "\n",
        "            # Move the model to the appropriate device\n",
        "            self.model.pipeline.to(self.device)\n",
        "\n",
        "            # Enable gradient checkpointing if supported\n",
        "            if hasattr(self.model, 'apply_gradient_checkpointing'):\n",
        "                self.model.apply_gradient_checkpointing()\n",
        "\n",
        "            scaler = torch.cuda.amp.GradScaler()\n",
        "            optimizer = torch.optim.AdamW(self.model.pipeline.unet.parameters(), lr=1e-5)\n",
        "\n",
        "            for epoch in range(num_epochs):\n",
        "                total_loss = 0\n",
        "                num_batches = 0\n",
        "\n",
        "                for batch in dataset:\n",
        "                    try:\n",
        "                        # Move batch to the correct device\n",
        "                        batch = {k: v.to(self.device) if torch.is_tensor(v) else v for k, v in batch.items()}\n",
        "\n",
        "                        # Clear gradients\n",
        "                        optimizer.zero_grad()\n",
        "\n",
        "                        # Forward pass with automatic mixed precision\n",
        "                        with torch.cuda.amp.autocast():\n",
        "                            loss = self.model.pipeline(batch)  # Forward pass\n",
        "                            total_loss += loss.item()\n",
        "\n",
        "                        # Backward pass with gradient scaling\n",
        "                        scaler.scale(loss).backward()\n",
        "                        scaler.step(optimizer)\n",
        "                        scaler.update()\n",
        "\n",
        "                        num_batches += 1\n",
        "                    except Exception as batch_error:\n",
        "                        print(f\"Error during batch processing: {batch_error}\")\n",
        "                        continue\n",
        "\n",
        "                # Print epoch statistics\n",
        "                avg_loss = total_loss / max(num_batches, 1)  # Avoid division by zero\n",
        "                print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "                # Clear CUDA cache and garbage collect after each epoch\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during training stage: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "z8WVXaz4CFz_"
      },
      "outputs": [],
      "source": [
        "def upload_images():\n",
        "    \"\"\"Allow users to upload images for training.\"\"\"\n",
        "    os.makedirs(\"uploaded_images\", exist_ok=True)\n",
        "    uploaded_files = files.upload()\n",
        "    for filename in uploaded_files.keys():\n",
        "        img = Image.open(filename)\n",
        "        img.save(f\"uploaded_images/{filename}\")\n",
        "        print(f\"Saved {filename} to uploaded_images/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zDlLJVS6CJWo"
      },
      "outputs": [],
      "source": [
        "class DriveImageDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_size: Tuple[int, int] = (512, 512),\n",
        "        transform = None\n",
        "    ):\n",
        "        \"\"\"Initialize dataset from Google Drive folder\"\"\"\n",
        "        self.folder_path = Path(IMAGE_DIR)\n",
        "        self._validate_drive_folder()\n",
        "        self.image_files = self._get_drive_images()\n",
        "        self.image_size = image_size\n",
        "        self.transform = transform or self._default_transform()\n",
        "        print(f\"Loaded dataset with {len(self.image_files)} images from {IMAGE_DIR}\")\n",
        "\n",
        "    def _validate_drive_folder(self):\n",
        "        if not self.folder_path.exists():\n",
        "            raise ValueError(f\"Drive image directory not found: {IMAGE_DIR}\")\n",
        "\n",
        "    def _get_drive_images(self) -> List[Path]:\n",
        "        files = list(self.folder_path.glob(\"*.jpg\")) + \\\n",
        "                list(self.folder_path.glob(\"*.png\"))\n",
        "        if not files:\n",
        "            raise ValueError(f\"No images found in Drive folder {IMAGE_DIR}\")\n",
        "        return files\n",
        "\n",
        "    def _default_transform(self):\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize(self.image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_files[idx]\n",
        "        try:\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return {\n",
        "                \"image\": image,\n",
        "                \"prompt\": f\"A landscape photo of {image_path.stem}\",\n",
        "                \"path\": str(image_path)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Drive image {image_path}: {e}\")\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_landscape_image(\n",
        "    model: OptimizedSDXL,\n",
        "    prompt: str,\n",
        "    processor: Optional[PromptProcessor] = None,\n",
        "    negative_prompt: Optional[str] = None,\n",
        "    num_inference_steps: int = 50,\n",
        "    max_attempts: int = 1\n",
        ") -> Optional[Image.Image]:\n",
        "    \"\"\"Generate landscape image with attempt limiting\"\"\"\n",
        "\n",
        "    attempt = 0\n",
        "    while attempt < max_attempts:\n",
        "        try:\n",
        "            print(f\"Attempt {attempt + 1}/{max_attempts} - Generating image...\")\n",
        "\n",
        "            # Process prompt if processor available\n",
        "            parameters = {}\n",
        "            if processor:\n",
        "                parameters = processor.process_prompt(prompt)\n",
        "\n",
        "            # Clear memory\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "            # Generate image\n",
        "            image = model.generate_image(\n",
        "                prompt=prompt,\n",
        "                negative_prompt=negative_prompt,\n",
        "                num_inference_steps=num_inference_steps,\n",
        "                **parameters\n",
        "            )\n",
        "\n",
        "            if image:\n",
        "                print(f\"Successfully generated image on attempt {attempt + 1}\")\n",
        "                return image\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error on attempt {attempt + 1}: {str(e)}\")\n",
        "\n",
        "        attempt += 1\n",
        "\n",
        "    print(\"Failed to generate image after maximum attempts\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "swYmgaykHnZS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "d0c80b22b70d426eb78a64ed769c5017",
            "1fb7de7f7c7b4015bfacc62ea43becad",
            "819d9ea3dc4f46e087cc9bc91ff84789",
            "a9b0c45fe3a944f08593a929ab3d0750",
            "eefed8cd3ed84177b6e28f7ab1095474",
            "3c8a15e5bb524b3eb8a377f1b8c28b9f",
            "ff503bf8c9944b93932c4a77a40b26b3",
            "441048a4856043c186924f8850741c44",
            "9e0a1958188c4aa59daf18d18329eb42",
            "46c27d9684e342479123683612f2831e",
            "e91bfd80cb1e4650bb5a74ab72a255d3",
            "2679e0e7edd84c13a101c41a6d53898c",
            "a765949207f5438daeff0963034f7267",
            "10a78a51c776451b86c1c82b1f3e525d",
            "cc485f70ed884fb1971a52e6ee431740",
            "defcf6681cae49f39121510e25ddb9dc",
            "132ab0ce878f40f0a05a3b7b7bd7c50b",
            "14978c08d5434a08803ae66cdd60e282",
            "b53e6c52c6da4ec1ad94279f22d7d4ad",
            "17a3bc8f6cb4460db0d4da1be156d860",
            "62ec96990a6a46e7b1b13c6de7cb3263",
            "0afa16dc47584e6fa937b429508f074e"
          ]
        },
        "id": "tLKkiKRNCSNz",
        "outputId": "a4a0c5d8-de59-4ba4-f5a6-3f0e1ddfb4a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset with 7 images from /content/drive/MyDrive/SDXL_images/landscape_images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0c80b22b70d426eb78a64ed769c5017"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline setup complete on device: cuda\n",
            "Starting epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-46d6ffd8b27f>:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2679e0e7edd84c13a101c41a6d53898c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training error: name 'CHECKPOINT_DIR' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py:147: RuntimeWarning: invalid value encountered in cast\n",
            "  images = (images * 255).round().astype(\"uint8\")\n"
          ]
        }
      ],
      "source": [
        "# Initialize components first\n",
        "dataset = DriveImageDataset(image_size=(512, 512))\n",
        "config = OptimizationConfig(image_size=(512, 512))\n",
        "model = OptimizedSDXL(config=config)\n",
        "\n",
        "# Call train_model with required arguments\n",
        "try:\n",
        "    train_model(\n",
        "        model=model,\n",
        "        dataset=dataset,\n",
        "        num_epochs=5,\n",
        "        batch_size=1,\n",
        "        save_interval=100\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"Training error: {str(e)}\")\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(\n",
        "    model: OptimizedSDXL,\n",
        "    dataset: DriveImageDataset,\n",
        "    num_epochs: int = 5,\n",
        "    batch_size: int = 1,\n",
        "    save_interval: int = 100\n",
        "):\n",
        "    \"\"\"Train model using Drive dataset\"\"\"\n",
        "    try:\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"Starting epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "            for batch_idx, batch in enumerate(dataloader):\n",
        "                # Process batch\n",
        "                images = batch[\"image\"]\n",
        "                prompts = batch[\"prompt\"]\n",
        "\n",
        "                # Generate images\n",
        "                generated = model.generate_image(\n",
        "                    prompt=prompts[0],  # Using first prompt\n",
        "                    num_inference_steps=50\n",
        "                )\n",
        "\n",
        "                # Save checkpoint to Drive\n",
        "                if batch_idx % save_interval == 0:\n",
        "                    checkpoint_path = os.path.join(\n",
        "                        CHECKPOINT_DIR,\n",
        "                        f\"checkpoint_e{epoch}_b{batch_idx}.pt\"\n",
        "                    )\n",
        "                    torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "                # Clear memory\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Training error: {str(e)}\")"
      ],
      "metadata": {
        "id": "GhB9F-OnKtkp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "czxItnMLCTZ3",
        "outputId": "f088c3c8-63cd-4fad-a0a6-b324d7ceea1c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "train_model() missing 2 required positional arguments: 'model' and 'dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-4dc2ba0c028a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: train_model() missing 2 required positional arguments: 'model' and 'dataset'"
          ]
        }
      ],
      "source": [
        "train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pl4RCy69ZRWH"
      },
      "outputs": [],
      "source": [
        "def generate_landscape_image(\n",
        "    model: OptimizedSDXL,\n",
        "    prompt: str,\n",
        "    processor: Optional[PromptProcessor] = None,\n",
        "    negative_prompt: Optional[str] = None,\n",
        "    num_inference_steps: int = 50\n",
        ") -> Optional[Image.Image]:\n",
        "    \"\"\"\n",
        "    Generate landscape image with prompt processing and memory optimization.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Process prompt if processor provided\n",
        "        if processor:\n",
        "            processed = processor.process_prompt(prompt)\n",
        "            parameters = processed.parameters\n",
        "        else:\n",
        "            parameters = {}\n",
        "\n",
        "        print(f\"Generating landscape image for prompt: '{prompt}'...\")\n",
        "\n",
        "        # Clear CUDA cache\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        # Generate image with processed parameters\n",
        "        image = model.generate_image(\n",
        "            prompt=prompt,\n",
        "            negative_prompt=negative_prompt,\n",
        "            num_inference_steps=num_inference_steps,\n",
        "            **parameters\n",
        "        )\n",
        "\n",
        "        # Save image\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        save_path = f\"landscape_image_{timestamp}.png\"\n",
        "        image.save(save_path)\n",
        "        print(f\"Landscape image saved at {save_path}\")\n",
        "\n",
        "        return image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating image: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWiXkzENh7p2"
      },
      "outputs": [],
      "source": [
        "# Initialize model and generate image\n",
        "config = OptimizationConfig(image_size=(256, 256))\n",
        "optimized_sdxl = OptimizedSDXL(config=config)\n",
        "\n",
        "# Generate an image\n",
        "landscape_prompt = \"A picturesque mountain range with a tranquil river flowing through it\"\n",
        "generate_landscape_image(optimized_sdxl, prompt=landscape_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hZUfE3GVE2F"
      },
      "outputs": [],
      "source": [
        "# 1. First, fix the generate_landscape_image function definition\n",
        "def generate_landscape_image(\n",
        "    model: OptimizedSDXL,\n",
        "    prompt: str,\n",
        "    negative_prompt: Optional[str] = None,\n",
        "    num_inference_steps: int = 50,\n",
        "    processor: Optional[PromptProcessor] = None  # Add processor parameter\n",
        ") -> Optional[Image.Image]:\n",
        "    \"\"\"Generate landscape image with prompt processing and memory optimization.\"\"\"\n",
        "    try:\n",
        "        # Process prompt if processor provided\n",
        "        parameters = {}\n",
        "        if processor:\n",
        "            parameters = processor.process_prompt(prompt)\n",
        "\n",
        "        print(f\"Generating image for prompt: '{prompt}'...\")\n",
        "\n",
        "        # Clear memory\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        # Generate with parameters\n",
        "        image = model.generate_image(\n",
        "            prompt=prompt,\n",
        "            negative_prompt=negative_prompt,\n",
        "            num_inference_steps=num_inference_steps,\n",
        "            **parameters\n",
        "        )\n",
        "\n",
        "        return image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating image: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2DUYxIoVE2G"
      },
      "outputs": [],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize processor and model\n",
        "    processor = PromptProcessor()\n",
        "    config = OptimizationConfig(image_size=(512, 512))\n",
        "    model = OptimizedSDXL(config=config)\n",
        "\n",
        "    # Generate image with processed prompt\n",
        "    prompt = \"A large mountain landscape with dramatic sunset lighting\"\n",
        "    image = generate_landscape_image(\n",
        "        model=model,\n",
        "        prompt=prompt,\n",
        "        negative_prompt=\"blur, distortion, low quality\",\n",
        "        num_inference_steps=50,\n",
        "        processor=processor  # Pass processor as a named argument\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d0c80b22b70d426eb78a64ed769c5017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fb7de7f7c7b4015bfacc62ea43becad",
              "IPY_MODEL_819d9ea3dc4f46e087cc9bc91ff84789",
              "IPY_MODEL_a9b0c45fe3a944f08593a929ab3d0750"
            ],
            "layout": "IPY_MODEL_eefed8cd3ed84177b6e28f7ab1095474"
          }
        },
        "1fb7de7f7c7b4015bfacc62ea43becad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c8a15e5bb524b3eb8a377f1b8c28b9f",
            "placeholder": "​",
            "style": "IPY_MODEL_ff503bf8c9944b93932c4a77a40b26b3",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "819d9ea3dc4f46e087cc9bc91ff84789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_441048a4856043c186924f8850741c44",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e0a1958188c4aa59daf18d18329eb42",
            "value": 7
          }
        },
        "a9b0c45fe3a944f08593a929ab3d0750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46c27d9684e342479123683612f2831e",
            "placeholder": "​",
            "style": "IPY_MODEL_e91bfd80cb1e4650bb5a74ab72a255d3",
            "value": " 7/7 [01:23&lt;00:00,  9.61s/it]"
          }
        },
        "eefed8cd3ed84177b6e28f7ab1095474": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c8a15e5bb524b3eb8a377f1b8c28b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff503bf8c9944b93932c4a77a40b26b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "441048a4856043c186924f8850741c44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e0a1958188c4aa59daf18d18329eb42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46c27d9684e342479123683612f2831e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e91bfd80cb1e4650bb5a74ab72a255d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2679e0e7edd84c13a101c41a6d53898c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a765949207f5438daeff0963034f7267",
              "IPY_MODEL_10a78a51c776451b86c1c82b1f3e525d",
              "IPY_MODEL_cc485f70ed884fb1971a52e6ee431740"
            ],
            "layout": "IPY_MODEL_defcf6681cae49f39121510e25ddb9dc"
          }
        },
        "a765949207f5438daeff0963034f7267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_132ab0ce878f40f0a05a3b7b7bd7c50b",
            "placeholder": "​",
            "style": "IPY_MODEL_14978c08d5434a08803ae66cdd60e282",
            "value": "100%"
          }
        },
        "10a78a51c776451b86c1c82b1f3e525d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b53e6c52c6da4ec1ad94279f22d7d4ad",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17a3bc8f6cb4460db0d4da1be156d860",
            "value": 50
          }
        },
        "cc485f70ed884fb1971a52e6ee431740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62ec96990a6a46e7b1b13c6de7cb3263",
            "placeholder": "​",
            "style": "IPY_MODEL_0afa16dc47584e6fa937b429508f074e",
            "value": " 50/50 [01:05&lt;00:00,  1.34s/it]"
          }
        },
        "defcf6681cae49f39121510e25ddb9dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "132ab0ce878f40f0a05a3b7b7bd7c50b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14978c08d5434a08803ae66cdd60e282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b53e6c52c6da4ec1ad94279f22d7d4ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a3bc8f6cb4460db0d4da1be156d860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62ec96990a6a46e7b1b13c6de7cb3263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0afa16dc47584e6fa937b429508f074e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}